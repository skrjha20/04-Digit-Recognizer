import numpy as np
import pandas as pd
import seaborn as sn
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from keras.utils.np_utils import to_categorical
from keras.models import Sequential, load_model
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization
from keras.optimizers import Adam
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import LearningRateScheduler, ModelCheckpoint

def build_model(X_train, y_train, X_val, y_val):
    model = Sequential()

    model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))
    model.add(BatchNormalization())
    model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))
    model.add(BatchNormalization())
    model.add(MaxPool2D(strides=(2, 2)))
    model.add(Dropout(0.25))

    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))
    model.add(BatchNormalization())
    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))
    model.add(BatchNormalization())
    model.add(MaxPool2D(strides=(2, 2)))
    model.add(Dropout(0.25))

    model.add(Flatten())
    model.add(Dense(512, activation='relu'))
    model.add(Dropout(0.25))
    model.add(Dense(1024, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(10, activation='softmax'))

    datagen = ImageDataGenerator(zoom_range=0.1, height_shift_range=0.1, width_shift_range=0.1, rotation_range=10)
    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=["accuracy"])
    annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)

    checkpointer = ModelCheckpoint(filepath="model_CNN.h5", verbose=0, save_best_only=True)
    hist = model.fit_generator(datagen.flow(X_train, y_train, batch_size=16),
                               steps_per_epoch=500,
                               epochs=20,  # Increase this when not on Kaggle kernel
                               verbose=2,  # 1 for ETA, 0 for silent
                               validation_data=(X_val, y_val),  # For speed
                               callbacks=[annealer, checkpointer])

    final_loss, final_acc = model.evaluate(X_val, y_val, verbose=0)
    print("Final loss: {0:.4f}, final accuracy: {1:.4f}".format(final_loss, final_acc))

    plt.figure(1)
    plt.plot(hist.history['loss'], color='b')
    plt.plot(hist.history['val_loss'], color='r')
    plt.title('model loss')
    plt.ylabel('Loss')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper right')
    plt.savefig("Model Loss")

    plt.figure(2)
    plt.plot(hist.history['acc'], color='b')
    plt.plot(hist.history['val_acc'], color='r')
    plt.title('Model Accuracy')
    plt.ylabel('Accuracy')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper right')
    plt.savefig("Model Accuracy")

def predict_val(model, X_val, y_val):
    y_hat = model.predict(X_val)
    y_pred = np.argmax(y_hat, axis=1)
    y_true = np.argmax(y_val, axis=1)
    cm = confusion_matrix(y_true, y_pred)

    df_cm = pd.DataFrame(cm, index=[i for i in "ABCDEFGHIJ"], columns=[i for i in "ABCDEFGHIJ"])
    plt.figure(3)
    plt.figure(figsize=(15, 7))
    sn.heatmap(df_cm, annot=True)
    plt.savefig("Confusion Matrix")

def predict_test(model, X_test, output_data):
    y_hat = model.predict(X_test, batch_size=64)
    y_pred = np.argmax(y_hat, axis=1)
    y_pred = pd.DataFrame(y_pred)
    y_pred.columns = ['Label']
    output = output_data.drop(['Label'], axis=1)
    output = pd.concat([output,y_pred], axis=1)
    output.to_csv("submission.csv", index=False)

if __name__ == "__main__":

    train_data = pd.read_csv("train.csv")
    test_data = pd.read_csv("test.csv")
    output_data = pd.read_csv("sample_submission.csv")

    y_train_data = train_data['label']
    X_train_data = train_data.drop(['label'], axis=1)
    X_train, X_val, y_train, y_val = train_test_split(X_train_data, y_train_data, test_size=0.1)

    X_train = X_train.values
    X_val   = X_val.values
    X_test  = test_data.values
    X_train = X_train.reshape(-1, 28, 28, 1)
    X_val   = X_val.reshape(-1, 28, 28, 1)
    X_test  = X_test.reshape(-1, 28, 28, 1)
    X_train = X_train.astype("float32") / 255
    X_val   = X_val.astype("float32") / 255
    X_test  = X_test.astype("float32") / 255

    y_train = to_categorical(y_train)
    y_val   = to_categorical(y_val)

    build_model(X_train, y_train, X_val, y_val)
    model = load_model('model_CNN.h5')
    predict_val(model, X_val, y_val)
    predict_test(model, X_test, output_data)
